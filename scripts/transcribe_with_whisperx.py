import os
import glob
import torch
import whisperx
import json

# âœ… å°‡ Hugging Face æ¨¡å‹å¿«å–ä½ç½®æ”¹åˆ°å°ˆæ¡ˆè³‡æ–™å¤¾
os.environ["HF_HOME"] = "D:\\NLP_Multimodal_Sentiment_Analysis\\.hf_cache"

# âœ… è¨­å®šåŸ·è¡Œè¨­å‚™ï¼ˆGPU æœ‰å‰‡ç”¨ï¼Œå¦å‰‡ç”¨ CPUï¼‰
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisperx.load_model("large-v3", device=device, compute_type="float32")

# âœ… å½±ç‰‡è³‡æ–™å¤¾èˆ‡æª”æ¡ˆåˆ—è¡¨
video_folder = "D:\\NLP_Multimodal_Sentiment_Analysis"
video_files = glob.glob(os.path.join(video_folder, "cut_*.mp4"))

# âœ… æ‰¹æ¬¡è™•ç†å½±ç‰‡
for video_path in video_files:
    filename = os.path.basename(video_path)
    name = os.path.splitext(filename)[0]

    print(f"ğŸ” æ­£åœ¨è™•ç†: {filename}")
    result = model.transcribe(video_path, language="zh")

    # âœ… å„²å­˜ json çµæœ
    output_path = os.path.join(video_folder, f"transcript_{name}.json")
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²å„²å­˜ï¼š{output_path}")
