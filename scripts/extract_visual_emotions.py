import os
import subprocess
import pandas as pd
from deepface import DeepFace
from tqdm import tqdm

# âœ… è¨­å®šè³‡æ–™å¤¾
project_root = "D:\\NLP_Multimodal_Sentiment_Analysis"
video_files = [f for f in os.listdir(project_root) if f.startswith("cut_") and f.endswith(".mp4")]
output_root = os.path.join(project_root, "visual_emotion_output")
os.makedirs(output_root, exist_ok=True)

for video in video_files:
    base = os.path.splitext(video)[0]  # e.g. cut_ç‹ç«‹è¯
    print(f"\nğŸï¸ è™•ç†å½±ç‰‡ï¼š{video}")
    
    # å»ºç«‹å½±ç‰‡å°ˆå±¬è³‡æ–™å¤¾
    video_dir = os.path.join(output_root, base)
    os.makedirs(video_dir, exist_ok=True)
    
    # === Step 1: æ“·å–æ¯ç§’ç•«é¢ ===
    frame_pattern = os.path.join(video_dir, "frame_%04d.jpg")
    video_path = os.path.join(project_root, video)
    cmd = f'ffmpeg -i "{video_path}" -vf fps=1 "{frame_pattern}" -hide_banner -loglevel error'
    subprocess.call(cmd, shell=True)
    print("âœ… å·²æ“·å–ç•«é¢")

    # å»ºç«‹ frame_second.csvï¼ˆæ™‚é–“å°æ‡‰ï¼‰
    frame_files = sorted([f for f in os.listdir(video_dir) if f.startswith("frame_") and f.endswith(".jpg")])
    frame_data = [{"frame_file": f, "second": i} for i, f in enumerate(frame_files)]
    df_frames = pd.DataFrame(frame_data)
    df_frames.to_csv(os.path.join(video_dir, "frame_second.csv"), index=False, encoding="utf-8-sig")

    # === Step 2: ä½¿ç”¨ DeepFace é æ¸¬æƒ…ç·’ ===
    visual_emotions = []
    for row in tqdm(frame_data, desc="ğŸ” è¡¨æƒ…åˆ†æä¸­"):
        img_path = os.path.join(video_dir, row["frame_file"])
        try:
            result = DeepFace.analyze(img_path=img_path, actions=['emotion'], enforce_detection=False)
            emotion = result[0]["dominant_emotion"]
            conf = result[0]["emotion"][emotion]
        except Exception as e:
            emotion = "error"
            conf = 0.0
        visual_emotions.append({
            "second": row["second"],
            "visual_emotion": emotion,
            "vis_confidence": round(conf, 4)
        })

    df_vis = pd.DataFrame(visual_emotions)
    df_vis.to_csv(os.path.join(video_dir, "visual_emotion.csv"), index=False, encoding="utf-8-sig")
    print("âœ… è¡¨æƒ…çµæœå·²å„²å­˜")

    # === Step 3: åˆä½µèªéŸ³æ™‚é–“æ ¼å­ ===
    timegrid_path = os.path.join(project_root, f"{base}_roberta3_fine_timegrid.csv")
    if os.path.exists(timegrid_path):
        df_timegrid = pd.read_csv(timegrid_path, encoding="utf-8-sig")
        merged = pd.merge(df_timegrid, df_vis, on="second", how="left").fillna("none")
        merged.to_csv(os.path.join(video_dir, "merged_timegrid.csv"), index=False, encoding="utf-8-sig")
        print("âœ… å¤šæ¨¡æ…‹æ™‚é–“æ ¼å­è¡¨å®Œæˆ")
    else:
        print("âš ï¸ ç„¡å°æ‡‰èªéŸ³ timegridï¼Œè«‹ç¢ºèªæª”æ¡ˆå­˜åœ¨")

print("\nğŸŒˆ æ‰€æœ‰å½±ç‰‡è™•ç†å®Œæˆï¼")
